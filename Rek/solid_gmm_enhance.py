
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.mixture import GaussianMixture as GMM
from tqdm.auto import tqdm
from abc import ABC, abstractmethod
from util.logger import logger
from .experence import debug_plot_gmm,visualize_gmm

class MathUtils:
    @staticmethod
    def sanitize_array(x, fill_for_nonfinite=0.0):
        x = np.asarray(x)
        if x.size == 0: return x
        out = x.astype(float, copy=True)
        mask = ~np.isfinite(out)
        if mask.any():
            out[mask] = fill_for_nonfinite
        return out

    @staticmethod
    def robust_normalize(score_array, clip_percentile=99.0):
        """æŠ—æ¥µç«¯å€¼çš„æ­¸ä¸€åŒ– (Robust Normalization)"""
        arr = np.array(score_array)
        limit = np.percentile(arr, clip_percentile)
        arr_clipped = np.clip(arr, a_min=None, a_max=limit)
        min_val = arr_clipped.min()
        max_val = arr_clipped.max()
        
        if max_val - min_val > 1e-6:
            return (arr_clipped - min_val) / (max_val - min_val)
        return np.zeros_like(arr)
    @staticmethod
    def minmax_normalize_columnwise(matrix):
        """
        label_wise normalize_array
        
        """
        # é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
        out = matrix.astype(float, copy=True)
        # é‡å°æ¯ä¸€è¡Œ (Column) æ‰¾ min å’Œ max
        min_vals = out.min(axis=0)
        max_vals = out.max(axis=0)
        
        # é¿å…é™¤ä»¥ 0 (å¦‚æœè©²æ¨™ç±¤æ‰€æœ‰åˆ†æ•¸éƒ½ä¸€æ¨£)
        range_vals = max_vals - min_vals
        range_vals[range_vals == 0] = 1e-8 
        
        # Broadcasting é‹ç®—: (N, C) - (C,) / (C,)
        out = (out - min_vals) / range_vals
        return out

class BaseScoreCalculator(ABC):
    """è¨ˆç®—åˆ†æ•¸çš„åŸºç¤ä»‹é¢ (Strategy Pattern)"""
    @abstractmethod
    def calculate(self, model, dataloader, device):
        """å›å‚³ (indices, scores)"""
        pass

class BaseNoiseFilter(ABC):
    """ç¯©é¸é›œè¨Šçš„åŸºç¤ä»‹é¢"""
    @abstractmethod
    def filter(self, scores, indices):
        """å›å‚³ (clean_indices, noisy_indices)"""
        pass

class StandardLossCalculator(BaseScoreCalculator):
    """è¨ˆç®—åŸå§‹ BCE Loss"""
    def calculate(self, model, dataloader, device):
        model.eval()
        scores = []
        indices = []
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="Calculating Standard Loss"):
                b_input_ids = batch['input_ids'].to(device)
                b_attn_mask = batch['attention_mask'].to(device)
                b_labels = batch['labels'].to(device)
                b_idx = batch['index']

                logits, _ = model(input_ids=b_input_ids, attention_mask=b_attn_mask)
                loss = F.binary_cross_entropy_with_logits(logits, b_labels.float(), reduction='none')
                loss_sum = loss.sum(dim=1)
                
                scores.extend(loss_sum.cpu().numpy())
                indices.extend(b_idx.numpy())
                
        return np.array(indices), np.array(scores)

class RankWeightedLossCalculator(BaseScoreCalculator):
    """è¨ˆç®— Rank-based Weighted Loss"""
    def __init__(self, theta=3.0):
        self.theta = theta

    def _calculate_rank_weight(self, logits):
        B, C = logits.shape
        idx_sorted = torch.argsort(logits, dim=1, descending=True)
        ranks = torch.empty_like(idx_sorted, dtype=torch.float, device=logits.device)
        base = torch.arange(1, C + 1, device=logits.device, dtype=torch.float).unsqueeze(0).expand(B, -1)
        ranks.scatter_(dim=1, index=idx_sorted, src=base)
        
        w = torch.log(ranks) + 1.0
        theta_tensor = torch.full_like(w, float(self.theta))
        w = torch.minimum(w, theta_tensor)
        return w

    def calculate(self, model, dataloader, device):
        model.eval()
        scores = []
        indices = []
        labels = []
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="Calculating Rank Weighted Loss"):
                b_input_ids = batch['input_ids'].to(device)
                b_attn_mask = batch['attention_mask'].to(device)
                b_labels = batch['labels'].to(device)
                b_idx = batch['index']
           
                logits, _ = model(input_ids=b_input_ids, attention_mask=b_attn_mask)
                loss = F.binary_cross_entropy_with_logits(logits, b_labels.float(), reduction='none')
                
                weights = self._calculate_rank_weight(logits=logits)

                weighted_loss = loss * weights

                scores.append(weighted_loss.cpu().numpy()) 
                indices.extend(b_idx.numpy())
                labels.append(b_labels.cpu().numpy())
        scores_np = np.vstack(scores)
        indices_np = np.array(indices)
        labels_np = np.vstack(labels)
        print(f"Debug Calculator Output:")
        print(f"  - Scores shape: {scores_np.shape}") # æ‡‰è©²æ˜¯ (53840, 54)
        print(f"  - Indices shape: {indices_np.shape}") # æ‡‰è©²æ˜¯ (53840,)
        
        return indices_np, scores_np, labels_np

class PrototypeDistanceCalculator(BaseScoreCalculator):

    """è¨ˆç®— Prototype Distance (CD)"""
    def __init__(self, args):
        self.args = args
        self.prototype_dict = {}

    def _get_threshold(self, logit_list):
        arr = MathUtils.sanitize_array(np.array(logit_list).reshape(-1))
        if arr.size == 0: return 1.0
        mean_logit = arr.mean()
        if mean_logit == 0 or not np.isfinite(mean_logit): return 1.0
        record = [(x / mean_logit) if x > mean_logit else 1.0 for x in arr if np.isfinite(x)]
        return float(np.mean(record)) if len(record) else 1.0

    def _build_prototypes(self, model, dataloader, device):
        feature_dict = {idx: None for idx in range(self.args.label_size)}
        logit_dict = {idx: None for idx in range(self.args.label_size)}
        
        model.eval()
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="Collecting features for Prototypes"):
                # é€™è£¡ç°¡åŒ–åƒæ•¸å‚³éï¼Œè¦–ä½ çš„ Dataset è€Œå®š
                input_ids = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                labels = batch["labels"].to(device).float()
                
                # å‡è¨­ forward å›å‚³ (logits, features)
                logits, features = model(input_ids=input_ids, attention_mask=attention_mask)
                
                B, H = features.shape
                C = self.args.label_size
                rep_np = features.cpu().numpy()
                log_np = logits.cpu().numpy()
                lab_np = labels.cpu().numpy()

                for b in range(B):
                    for c in range(C):
                        if lab_np[b, c] == 1:
                            vec = rep_np[b:b+1, :]
                            lg = log_np[b:b+1, c:c+1]
                            if feature_dict[c] is None:
                                feature_dict[c] = vec
                                logit_dict[c] = lg
                            else:
                                feature_dict[c] = np.vstack((feature_dict[c], vec))
                                logit_dict[c] = np.vstack((logit_dict[c], lg))
        
        # Aggregate
        for key in feature_dict.keys():
            feat_list = feature_dict[key]
            log_list = logit_dict[key]
            if log_list is None: log_list = np.random.rand(1)
            thr = self._get_threshold(log_list)
            
            # Get single prototype
            if feat_list is None:
                proto = np.zeros(features.shape[1])
            else:
                # ç°¡åŒ–çš„ prototype è¨ˆç®—
                logs = MathUtils.sanitize_array(np.array(log_list).reshape(-1), -np.inf)
                feats = MathUtils.sanitize_array(np.array(feat_list))
                mask = logs > float(thr)
                if np.any(mask):
                    cand = feats[mask]
                    proto = np.nanmean(cand, axis=0) if cand.size > 0 else np.nanmean(feats, axis=0)
                else:
                    proto = np.nanmean(feats, axis=0)
                
            self.prototype_dict[key] = np.nan_to_num(proto)

    def _compute_vectorized_cd(self, features, device):
        B, H = features.shape
        C = len(self.prototype_dict)
        protos = []
        for i in range(C):
            p = self.prototype_dict.get(i)
            if p is None: p = np.zeros(H)
            protos.append(torch.tensor(p, dtype=features.dtype, device=device))
        
        protos_tensor = torch.stack(protos) # [C, H]
        # features [B, 1, H], protos [1, C, H]
        sim = F.cosine_similarity(features.unsqueeze(1), protos_tensor.unsqueeze(0), dim=2, eps=1e-8)
        # dist = 1.0 - sim
        dist = -1*sim
        
        # Handle empty prototypes (masking)
        has_proto = (protos_tensor.abs().sum(dim=1) > 0).float().unsqueeze(0)
        dist = dist * has_proto + (1.0 - has_proto) * 1.0
        return dist

    def calculate(self, model, dataloader, device):
        # 1. Build Prototypes first
        self._build_prototypes(model, dataloader, device)
        
        # 2. Compute Distances
        model.eval()
        scores = []
        indices = []
        labels = []
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="Calculating Prototype Distance"):
                b_input_ids = batch['input_ids'].to(device)
                b_attn_mask = batch['attention_mask'].to(device)
                b_labels = batch['labels'].to(device)
                b_idx = batch['index']
                
                _, features = model(input_ids=b_input_ids, attention_mask=b_attn_mask)
                
                # è¨ˆç®—è·é›¢çŸ©é™£ [B, C]
                dists = self._compute_vectorized_cd(features, device)
                
                # é€™è£¡ä½¿ç”¨ Sum ä½œç‚ºè©²æ¨£æœ¬çš„æ•´é«”åˆ†æ•¸ (ä¿æŒèˆ‡ REL ä¸€è‡´)
                # dists = torch.clamp(dists, 0.0, 1.0)
                
                
                scores.append(dists.cpu().numpy())
                indices.extend(b_idx.numpy())
                labels.append(b_labels.cpu().numpy())
                

        scores_np = np.vstack(scores)
        labels_np = np.vstack(labels)
        indices_np = np.array(indices)
        return indices_np, scores_np, labels_np
    

class GMMNoiseFilter(BaseNoiseFilter):
    """ä½¿ç”¨ GMM äºŒåˆ†æ³•é€²è¡Œç¯©é¸"""
    def __init__(self, n_components=2, threshold=0.5):
        self.n_components = n_components
        self.threshold = threshold

    def filter(self, scores, indices):
        scores = np.asarray(scores, dtype=float)
        indices = np.asarray(indices)
        
        # --- å½¢ç‹€è¨ºæ–· ---
        N_indices = len(indices)
        N_scores = len(scores)
        
        print(f"[{self.__class__.__name__}] Input Check -> Scores: {scores.shape}, Indices: {indices.shape}")
        print(f"  - N_indices: {N_indices}, N_scores: {N_scores}")
        if scores.ndim == 2 and scores.shape[0] == N_indices:
            print(f"  > åµæ¸¬åˆ°çŸ©é™£åˆ†æ•¸ï¼Œæ­£åœ¨èšåˆ (Sum axis=1)...")
            scores = scores.sum(axis=1)

        # æƒ…æ³ B: Scores æ˜¯ [N] ä¸”é•·åº¦ä¸€è‡´ -> æ­£å¸¸æƒ…æ³
        elif scores.ndim == 1 and N_scores == N_indices:
            pass # é€™è£¡ä¸ç”¨åšä»»ä½•äº‹
            
        # 3. è™•ç† Flatten å¾Œé•·åº¦ä¸åŒ¹é…çš„æƒ…æ³ (é˜²å‘†)
        # å¦‚æœ scores å·²ç¶“è¢«æ”¤å¹³äº† (1D)ï¼Œä½†é•·åº¦æ˜¯ indices çš„å€æ•¸ (ä¾‹å¦‚ 181710 vs 53840)
        if scores.ndim == 1 and len(scores) != len(indices):
            if len(scores) > len(indices) and len(scores) % len(indices) == 0:
                num_classes = len(scores) // len(indices)
                print(f"[{self.__class__.__name__}] åµæ¸¬åˆ°æ”¤å¹³çš„ Multi-label è¼¸å…¥ã€‚æ­£åœ¨ Reshape ä¸¦èšåˆ...")
                scores = scores.reshape(len(indices), num_classes).sum(axis=1)
            else:
                # å¦‚æœç„¡æ³•æ•´é™¤ï¼Œä»£è¡¨è³‡æ–™çœŸçš„å°ä¸èµ·ä¾†ï¼Œå¿…é ˆå ±éŒ¯
                raise ValueError(f"ç¶­åº¦åš´é‡éŒ¯èª¤ï¼Scores: {len(scores)}, Indices: {len(indices)}ã€‚ç„¡æ³•å°é½Šã€‚")
            
        X = scores.reshape(-1, 1)
        
        # Fit GMM
        gmm = GMM(n_components=self.n_components, max_iter=100, tol=1e-2, reg_covar=5e-4)
        gmm.fit(X)
        
        # æ‰¾å‡º Mean è¼ƒå°çš„é‚£ç¾¤ (å‡è¨­ Loss/Distance å°çš„æ˜¯ä¹¾æ·¨çš„) 
        clean_idx = gmm.means_.argmin()
        probs = gmm.predict_proba(X)
        prob_clean = probs[:, clean_idx]
        
        # Thresholding
        is_clean = prob_clean > self.threshold
        
        clean_indices = indices[is_clean]
        noisy_indices = indices[~is_clean]
        
        print(f"[{self.__class__.__name__}] Filter Report:")
        print(f"  - Total: {len(indices)}")
        print(f"  - Clean: {len(clean_indices)} ({len(clean_indices)/len(indices):.2%})")
        print(f"  - Noisy: {len(noisy_indices)} ({len(noisy_indices)/len(indices):.2%})")
        
        return clean_indices, noisy_indices
    
    def _run_gmm_on_subset(self, scores_subset):
        """
        å…§éƒ¨ helperï¼šåœ¨å­é›†ä¸ŠåŸ·è¡Œ GMM ä¸¦å›å‚³ã€Œå±¬æ–¼ä¹¾æ·¨ç¾¤(ä½åˆ†ç¾¤)çš„æ©Ÿç‡ã€
        """
        if len(scores_subset) <= 1:
            return None
            
        data = scores_subset.reshape(-1, 1)
        gmm = GMM(n_components=2, max_iter=100, tol=1e-2, reg_covar=5e-4, random_state=0)
        gmm.fit(data)
        
        # æ‰¾å‡º Mean è¼ƒå°çš„é‚£ç¾¤ (ä»£è¡¨ Low Loss / Clean)
        clean_comp_idx = gmm.means_.argmin()
        probs_all = gmm.predict_proba(data)
        
        # å›å‚³ "å±¬æ–¼ä¹¾æ·¨ç¾¤" çš„æ©Ÿç‡
        return probs_all[:,0]
    
    def _apply_band_correction_analyzed(probs, y_noisy, args, y_clean):
        """
        probs:    æ ¡æ­£éšæ®µçš„é æ¸¬æ©Ÿç‡
        y_noisy:  æ··å…¥é›œè¨Šéšæ®µçš„æ¨™ç±¤ (Input)
        y_clean:  è³‡æ–™ä¹¾æ·¨éšæ®µçš„æ¨™ç±¤ (Ground Truth)
        """
        
        # 1. åŸ·è¡Œæ ¡æ­£é‚è¼¯ (å–å¾— y_corrected)
        band = (0.5 - args.epsilon, 0.5 + args.epsilon)
        probs = np.nan_to_num(probs, nan=0.5)
        
        # ç”Ÿæˆæ ¡æ­£å¾Œçš„æ¨™ç±¤ (Soft labels)
        y_corrected_soft = np.where(probs > 0.5 + args.epsilon, 1.0,
                        np.where(probs < 0.5 - args.epsilon, 0.0, 
                        probs))
        
        # ç‚ºäº†é€²è¡Œ 0/1 ç‹€æ…‹æ¯”å°ï¼Œæˆ‘å€‘å°‡æ ¡æ­£çµæœè½‰ç‚ºç¡¬æ¨™ç±¤
        # æ³¨æ„ï¼šé€™è£¡å‡è¨­ soft label > 0.5 å°±æ˜¯ 1ï¼Œæ‚¨å¯ä»¥ä¾éœ€æ±‚èª¿æ•´
        y_corrected = (y_corrected_soft > 0.5).astype(int)
        
        # ç¢ºä¿è¼¸å…¥éƒ½æ˜¯ numpy int æ ¼å¼
        if hasattr(y_clean, 'cpu'): y_clean = y_clean.cpu().numpy().astype(int)
        if hasattr(y_noisy, 'cpu'): y_noisy = y_noisy.cpu().numpy().astype(int)
        
        # 2. è¨ˆç®—ä¸‰éšæ®µç‹€æ…‹ç¢¼ (Magic Code)
        # Code = Clean(4) + Noisy(2) + Corrected(1)
        # ä¾‹å¦‚: 101 -> 4 + 0 + 1 = 5
        state_codes = (y_clean << 2) | (y_noisy << 1) | y_corrected
        
        # 3. çµ±è¨ˆèˆ‡åˆ†é¡
        stats = {
            # --- (A) æˆåŠŸä¿®å¾© (åŸæœ¬æœ‰é›œè¨Š -> ä¿®å¥½äº†) ---
            '101 (æ ¡æ­£å°äº†)': np.sum(state_codes == 5), # Clean=1, Noisy=0, Corr=1
            '010 (æ ¡æ­£å°äº†)': np.sum(state_codes == 2), # Clean=0, Noisy=1, Corr=0
            
            # --- (B) ç ´å£æ€§æ ¡æ­£ (åŸæœ¬æ²’é›œè¨Š -> æ”¹å£äº†) ---
            '110 (æ ¡æ­£éŒ¯äº†)': np.sum(state_codes == 6), # Clean=1, Noisy=1, Corr=0
            '001 (æ ¡æ­£éŒ¯äº†)': np.sum(state_codes == 1), # Clean=0, Noisy=0, Corr=1
            
            # --- (C) ç„¡æ•ˆæ ¡æ­£/æ¼æ”¹ (åŸæœ¬æœ‰é›œè¨Š -> æ²’ä¿®åˆ°) ---
            '100 (æ²’æ ¡æ­£åˆ°)': np.sum(state_codes == 4), # Clean=1, Noisy=0, Corr=0
            '011 (æ²’æ ¡æ­£åˆ°)': np.sum(state_codes == 3), # Clean=0, Noisy=1, Corr=1
            
            # --- (D) æ­£ç¢ºä¿æŒ (åŸæœ¬æ²’é›œè¨Š -> ä¿æŒåŸæ¨£) ---
            '111 (ä¸éœ€è¦æ ¡æ­£)': np.sum(state_codes == 7),
            '000 (ä¸éœ€è¦æ ¡æ­£)': np.sum(state_codes == 0),
        }

        # 4. æ¼‚äº®çš„æ‰“å°è¼¸å‡º
        print(f"\n{'='*10} Correction Analysis {'='*10}")
        print(f"Total Samples: {len(y_clean)}")
        
        print(f"\n[ğŸŸ¢ Success - é›œè¨ŠæˆåŠŸè¢«ç§»é™¤]")
        print(f"  101 (åŸæœ¬æ˜¯1, è®Šæˆ0, ä¿®å›1): {stats['101 (æ ¡æ­£å°äº†)']}")
        print(f"  010 (åŸæœ¬æ˜¯0, è®Šæˆ1, ä¿®å›0): {stats['010 (æ ¡æ­£å°äº†)']}")
        
        print(f"\n[ğŸ”´ Damage - ä¹¾æ·¨è³‡æ–™è¢«æ”¹å£]")
        print(f"  110 (åŸæœ¬æ˜¯1, æ²’è®Š, å»æ”¹æˆ0): {stats['110 (æ ¡æ­£éŒ¯äº†)']}")
        print(f"  001 (åŸæœ¬æ˜¯0, æ²’è®Š, å»æ”¹æˆ1): {stats['001 (æ ¡æ­£éŒ¯äº†)']}")
        
        print(f"\n[âš ï¸ Missed - é›œè¨Šä¾ç„¶å­˜åœ¨]")
        print(f"  100 (åŸæœ¬æ˜¯1, è®Šæˆ0, æ²’ä¿®å›ä¾†): {stats['100 (æ²’æ ¡æ­£åˆ°)']}")
        print(f"  011 (åŸæœ¬æ˜¯0, è®Šæˆ1, æ²’ä¿®å›ä¾†): {stats['011 (æ²’æ ¡æ­£åˆ°)']}")
        
        print(f"\n[âšª Keep - æ­£ç¢ºä¿æŒä¸å‹•]")
        print(f"  111 & 000 (è³‡æ–™åŸæœ¬ä¹¾æ·¨ä¸”æœªè¢«ä¿®æ”¹): {stats['111 (ä¸éœ€è¦æ ¡æ­£)'] + stats['000 (ä¸éœ€è¦æ ¡æ­£)']}")
        print(f"{'='*40}\n")

        return y_corrected_soft
    def _apply_band_correction(self, probs,y, args):
        """
        å…§éƒ¨ helperï¼šå¥—ç”¨ epsilon band é€²è¡Œæ•¸å€¼æ ¡æ­£
        probs: å±¬æ–¼ 'ä¹¾æ·¨/æ­£é¡' çš„æ©Ÿç‡å€¼ (1D array)
        """
        band = (0.5 - args.epsilon, 0.5 + args.epsilon)
        
        # çµ±è¨ˆè½åœ¨æ¨¡ç³Šåœ°å¸¶çš„æ•¸é‡ (åƒ…ä¾› Debug)
        n_mid = np.sum((probs >= band[0]) & (probs <= band[1]))
        if n_mid > 0:
            print(f'  [Correction] Uncertain samples (in band): {n_mid} / {len(probs)}')

        # è™•ç† NaNï¼Œé è¨­ç‚º 0.5 (ä¸ç¢ºå®š)
        probs = np.nan_to_num(probs, nan=0.5)
        

        # ä¸­é–“ -> ä¿æŒåŸå§‹æ©Ÿç‡ (Soft Label)
        out = np.where(probs > 0.5 + args.epsilon, y,
              np.where(probs < 0.5 - args.epsilon, 1-y, probs))
        
        return out.astype(float)

    def correction(self, scores, labels, args):
        """
        é€²éšæ ¡æ­£ï¼šé‡å°æ­£æ¨£æœ¬é€²è¡Œ GMM é‡ç®—ä¸¦ä¿®æ­£æ¨™ç±¤
        
        Args:
            scores: [N] æ‰€æœ‰çš„åˆ†æ•¸ (HSM score æˆ– Loss)
            labels: [N] åŸå§‹æ¨™ç±¤ (0 æˆ– 1)
            args: åŒ…å« args.epsilon çš„åƒæ•¸ç‰©ä»¶
        Returns:
            corrected_labels: [N] æ ¡æ­£å¾Œçš„æ¨™ç±¤ (æµ®é»æ•¸ï¼ŒåŒ…å« 0.0, 1.0 æˆ–ä¸­é–“å€¼)
        """
        print(f"[{self.__class__.__name__}] Running Correction...")
        
        # 1. è³‡æ–™å‰è™•ç† è³‡æ–™æ”¤å¹³
        scores_flat = np.asarray(scores, dtype=float).ravel()
        labels_flat = np.asarray(labels, dtype=int).ravel()
        
        # ğŸ” æª¢æŸ¥é»ï¼šç¾åœ¨é€™è£¡çµ•å°ä¸æœƒå ±éŒ¯äº†
        if len(scores_flat) != len(labels_flat):
            raise ValueError(f"Shape mismatch! Scores: {len(scores_flat)}, Labels: {len(labels_flat)}")

        scores_flat = np.nan_to_num(scores_flat, nan=1.0, posinf=1.0, neginf=0.0)

        # 2. æ¥ä¸‹ä¾†çš„é‚è¼¯è·Ÿä¹‹å‰ä¸€æ¨£
        corrected_labels_flat = labels_flat.astype(float).copy()
        pos_f = 1
        neg_f = 0
        pos_mask = (labels_flat == pos_f) # é€™æ™‚å€™é•·åº¦ä¸€è‡´ï¼ŒMask é‹ä½œæ­£å¸¸
        neg_mask = (labels_flat == neg_f)

        # === A. æ­£æ¨£æœ¬è™•ç† ===
        pos_scores = scores_flat[pos_mask] 
        print(f"  [+] Processing {len(pos_scores)} positive labels...")
        
        if len(pos_scores) > 1:

            pro_b_clean_pos = self._run_gmm_on_subset(pos_scores)
            if pro_b_clean_pos is not None:
                new_pos_labels = self._apply_band_correction(pro_b_clean_pos ,pos_f, args)
                corrected_labels_flat[pos_mask] = new_pos_labels
                

        # === B. è² æ¨£æœ¬è™•ç† ===
        neg_scores = scores_flat[neg_mask]
        print(f"  [-] Processing {len(neg_scores)} negative labels...")
        
        if len(neg_scores) > 1:
            pro_b_clean_neg = self._run_gmm_on_subset(neg_scores)
            if pro_b_clean_neg is not None:
                new_neg_labels = self._apply_band_correction(pro_b_clean_neg,neg_f, args)
                corrected_labels_flat[neg_mask] = new_neg_labels

        # 3. æœ€å¾Œçœ‹ä½ è¦å›å‚³æ”¤å¹³çš„çµæœï¼Œé‚„æ˜¯ Reshape å›å»
        # å¦‚æœ Dataset é æœŸçš„æ˜¯æ”¤å¹³çš„ Labelï¼Œå°±ç›´æ¥å›å‚³
        # å¦‚æœ Dataset é æœŸçš„æ˜¯ [N, C]ï¼Œè«‹åš reshape
        # return corrected_labels_flat.reshape(labels.shape) 
        corrected_labels = corrected_labels_flat.reshape(labels.shape)
        for label in range(labels.shape[1]):
            num_pos = np.sum(labels[:, label] == 1)
            num_neg = np.sum(labels[:, label] == 0)
            num_pos_corrected = np.sum(corrected_labels[:, label] == 1)
            num_neg_corrected = np.sum(corrected_labels[:, label] == 0)
            logger.info(f"  [Label {label} Correction Report]")
            logger.info(f"    - Original Positives: {num_pos}, Negatives: {num_neg}")
            # è¨‚æ­£çµæœ origin -flip
            pos_flip_neg= np.sum((labels[:, label] == 1) & (corrected_labels[:, label] == 0))
            neg_flip_pos= np.sum((labels[:, label] == 0) & (corrected_labels[:, label] == 1))
            
            logger.info("    - Total Changes:")
            logger.info(f"    - Positives flipped to Negative (1->0): {pos_flip_neg}")
            logger.info(f"    - Negatives flipped to Positive (0->1): {neg_flip_pos}")
            logger.info(f"    - After Correction: Positives: {num_pos_corrected}, Negatives: {num_neg_corrected}")
            print(f"  > å®Œæˆ {label} å€‹é¡åˆ¥çš„ç¨ç«‹æ ¡æ­£ã€‚")
        return corrected_labels
    

    def correction_perlabel(self, scores, labels, args):
        print(f"[{self.__class__.__name__}] Running Per-Label GMM Correction...")
        scores = np.asarray(scores, dtype=float)
        labels = np.asarray(labels, dtype=int)
        scores = np.nan_to_num(scores, nan=1.0, posinf=1.0, neginf=0.0)
        
        N, num_classes = scores.shape
        
        # å»ºç«‹è¼¸å‡ºçš„çŸ©é™£ (è¤‡è£½ä¸€ä»½)
        refined_labels = labels.astype(float).copy()
        
        # ç”¨ä¾†çµ±è¨ˆé€²åº¦çš„ bar
        iterator = range(num_classes)
        # å¦‚æœé¡åˆ¥å¾ˆå¤šï¼Œå¯ä»¥è€ƒæ…®ç”¨ tqdm åŒ…èµ·ä¾†: tqdm(range(num_classes), desc="Label Correction")
        
        # 2. é‡å°æ¯ä¸€å€‹é¡åˆ¥ (Column) ç¨ç«‹è™•ç†
        for c in iterator:


            stats = {
            "pos_origin": 0,
            "neg_origin": 0,
            "pos_flipped_to_neg": 0, # 1 -> 0 (æ‰¾å‡ºå‡æ­£ä¾‹)
            "neg_flipped_to_pos": 0, # 0 -> 1 (æ‰¾å‡ºå‡è² ä¾‹)
            "soft_labels": 0,        # è®Šæˆ 0.x (ä¸ç¢ºå®š)
            
        }
            # å–å‡ºç¬¬ c å€‹é¡åˆ¥çš„æ‰€æœ‰æ¨£æœ¬æ•¸æ“š
            col_scores = scores[:, c]  # [N]
            col_labels = labels[:, c]  # [N]
            
            # å®šç¾© Mask
            pos_f = 1
            neg_f = 0

            pos_mask = (col_labels == pos_f)
            neg_mask = (col_labels == neg_f)
            
            # -------------------------------------------
            # (A) è©²é¡åˆ¥çš„æ­£æ¨£æœ¬ (Positive) æ ¡æ­£
            # -------------------------------------------
            pos_scores_c = col_scores[pos_mask]
            
            # åªæœ‰ç•¶è©²é¡åˆ¥çš„æ­£æ¨£æœ¬å¤ å¤šæ™‚ï¼Œæ‰è·‘ GMM (é¿å… sample å¤ªå°‘ GMM ç‚¸é–‹)
            target_watch_list = [0,1,3,4,5,6,8,9,11,12,13,14]  # ä½ å¯ä»¥æŒ‡å®šä¸€äº›é¡åˆ¥ä¾†ç•«åœ–æª¢æŸ¥
            if len(pos_scores_c) > 1:
                prob_clean = self._run_gmm_on_subset(pos_scores_c)
                if c in target_watch_list:
                    # é¡¯ç¤ºçµæœ
                    visualize_gmm(pos_scores_c, class_name=c, subset_type=f"Pos_Original{args.alpha}",save_dir=f"gmm_debug_plots{args.alpha}")
                if prob_clean is not None:
                    # 2. å‚³å…¥æ©Ÿç‡ï¼ŒTarget=1.0
                    # Probé«˜(ä¹¾æ·¨) -> ç¶­æŒ 1
                    # Probä½(é›œè¨Š) -> ç¿»è½‰ç‚º 0
                    new_pos = self._apply_band_correction(prob_clean, 1.0, args)
                    refined_labels[pos_mask, c] = new_pos
                # --- çµ±è¨ˆè®ŠåŒ– ---
                # åŸæœ¬æ˜¯ 1ï¼Œè®Šæˆäº† 0 (å®Œå…¨ç¿»è½‰)
                flipped_0 = np.sum(new_pos == 0.0)
                # è®Šæˆäº†è»Ÿæ¨™ç±¤ (0 < x < 1)
                soft = np.sum((new_pos > 0.0) & (new_pos < 1.0))
                stats['pos_origin'] = len(pos_scores_c)
                stats["pos_flipped_to_neg"] += flipped_0
                stats["soft_labels"] += soft
            # -------------------------------------------
            # (B) è©²é¡åˆ¥çš„è² æ¨£æœ¬ (Negative) æ ¡æ­£
            neg_scores_c = col_scores[neg_mask]
            if len(neg_scores_c) > 1:
                prob_clean = self._run_gmm_on_subset(neg_scores_c)
                if c in target_watch_list:

                    visualize_gmm(neg_scores_c, class_name=c, subset_type=f"Neg_Original{args.alpha}",save_dir=f"gmm_debug_plots{args.alpha}")
                if prob_clean is not None:
                    # 2. å‚³å…¥æ©Ÿç‡ï¼ŒTarget=0.0
                    # Probé«˜(ä¹¾æ·¨) -> ç¶­æŒ 0
                    # Probä½(é›œè¨Š) -> ç¿»è½‰ç‚º 1
                    new_neg = self._apply_band_correction(prob_clean, 0.0, args)
                    refined_labels[neg_mask, c] = new_neg
                # --çµ±è¨ˆ
                flipped_1 = np.sum(new_neg == 1.0)
                # è®Šæˆäº†è»Ÿæ¨™ç±¤
                soft = np.sum((new_neg > 0.0) & (new_neg < 1.0))
                stats['neg_origin'] =len(neg_scores_c)
                stats["neg_flipped_to_pos"] += flipped_1
                stats["soft_labels"] += soft
            # --- æ¯å€‹é¡åˆ¥çš„æ ¡æ­£å ±å‘Š ---
            logger.info(f"  [Label {c} Correction Report]")
            logger.info(f"    - Original Positives: {stats['pos_origin']}, Negatives: {stats['neg_origin']}")
            # è¨‚æ­£çµæœ origin -flip
            pos_change=stats['pos_origin']- stats['pos_flipped_to_neg']+stats['neg_flipped_to_pos']
            neg_change=stats['neg_origin']- stats['neg_flipped_to_pos']+stats['pos_flipped_to_neg']
            logger.info("    - Total Changes:")
            logger.info(f"    - Positives flipped to Negative (1->0): {stats['pos_flipped_to_neg']}")
            logger.info(f"    - Negatives flipped to Positive (0->1): {stats['neg_flipped_to_pos']}")
            logger.info(f"    - Soft Labels assigned: {stats['soft_labels']}")
            logger.info(f"    - After Correction: Positives: {pos_change}, Negatives: {neg_change}")

        print(f"  > å®Œæˆ {num_classes} å€‹é¡åˆ¥çš„ç¨ç«‹æ ¡æ­£ã€‚")
        
        return refined_labels
    
# è² è²¬æå–åˆ†æ•¸ä¸¦ç¯©é¸é›œè¨Šçš„ Pipeline   
class NoiseSelectionPipeline:
    def __init__(self, calculator: BaseScoreCalculator, filter_strategy: BaseNoiseFilter):
        self.calculator = calculator
        self.filter_strategy = filter_strategy

    def run(self, model, dataloader, device):
        print("1. Calculating Scores...")
        indices, scores,labels = self.calculator.calculate(model, dataloader, device)
        
        print("2. Filtering Noise...")
        clean_ids, noisy_ids = self.filter_strategy.filter(scores, indices)
        
        return clean_ids, noisy_ids, scores, labels

class HSMHybridPipeline:
    """
    å°ˆé–€è™•ç† HSM é€™ç¨®éœ€è¦çµåˆå…©ç¨®åˆ†æ•¸çš„è¤‡é›œæµç¨‹
    é€™æ˜¯ä¸€å€‹æ›´é«˜éšçš„ Orchestrator
    """
    def __init__(self, rel_calculator, cd_calculator, filter_strategy, alpha=0.5):
        self.rel_calc = rel_calculator
        self.cd_calc = cd_calculator
        self.filter_strategy = filter_strategy
        self.alpha = alpha

    def run(self, model, dataloader, device):
        print("ğŸš€ Starting HSM Hybrid Selection...")
        
        # 1. åˆ†åˆ¥è¨ˆç®—å…©ç¨®åˆ†æ•¸
        idx1, rel_scores,labels = self.rel_calc.calculate(model, dataloader, device)
        # æ³¨æ„: é€™è£¡å‡è¨­ dataloader é †åºå›ºå®šï¼Œidx1 æ‡‰è©²ç­‰æ–¼ idx2ã€‚
        # åš´è¬¹ä½œæ³•æ‡‰è©²è¦åš index matchingï¼Œé€™è£¡ç°¡åŒ–è™•ç†ã€‚
        _, cd_scores,_= self.cd_calc.calculate(model, dataloader, device)
        
        # 2. è¨ºæ–· (Optional)
        print(f"  - REL Max: {rel_scores.max():.4f}, Mean: {rel_scores.mean():.4f}")
        print(f"  - CD Max: {cd_scores.max():.4f}, Mean: {cd_scores.mean():.4f}")
        
        # 3. æ­¸ä¸€åŒ–
        rel_norm = MathUtils.minmax_normalize_columnwise(rel_scores)
        cd_norm = MathUtils.minmax_normalize_columnwise(cd_scores)
        
        # 4. èåˆ (Fusion)
        final_score = rel_norm * self.alpha + cd_norm * (1 - self.alpha)
        final_scores = final_score
        clean_ids, noisy_ids = self.filter_strategy.filter(final_scores, idx1)
        # 5. ç¯©é¸
        return clean_ids, noisy_ids, final_scores, labels


    def run_score_only(self, model, dataloader, device):
        """åªè¨ˆç®—ä¸¦èåˆåˆ†æ•¸ï¼Œä¸é€²è¡Œç¯©é¸/æ ¡æ­£ (ç‚ºäº†å¤–éƒ¨åƒæ•¸æœå°‹ç”¨)"""
        print("ğŸš€ Pipeline: Calculating Scores Only...")
        
        # 1. è¨ˆç®—
        idx1, rel_scores, labels = self.rel_calc.calculate(model, dataloader, device)
        _, cd_scores, _ = self.cd_calc.calculate(model, dataloader, device)
        
        # 2. æ­¸ä¸€åŒ–
        rel_norm = MathUtils.minmax_normalize_columnwise(rel_scores)
        cd_norm = MathUtils.minmax_normalize_columnwise(cd_scores)
        
        # 3. èåˆ
        hsm_scores = rel_norm * self.alpha + cd_norm * (1 - self.alpha)
        
        # å›å‚³åˆ†æ•¸ï¼Œè®“å¤–éƒ¨è¿´åœˆå»æ±ºå®šæ€éº¼åˆ‡
        return hsm_scores, labels, idx1
# 